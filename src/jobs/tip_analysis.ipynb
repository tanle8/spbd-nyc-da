{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tip Analysis\n",
    "\n",
    "- Assess the percentage of tips by trip.\n",
    "- Investigate geographical variations in tipping and the relationship between tipping amounts and trip distances.\n",
    "- Study variations in tipping by time of day, week, and notable periods (e.g., holidays).\n",
    "- Explore the impact of different payment types on tipping behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Local Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/25 13:53:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/25 13:53:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or retrieve a Spark session\n",
    "spark = SparkSession.builder.appName(\"Tip Analysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "TRAIN_PROCESSED = \"../../data/processed/yellow_tripdata_2024-01.parquet\"\n",
    "\n",
    "df = spark.read.parquet(TRAIN_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Assess the Percentage of Tips by Trip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|    tip_percentage|\n",
      "+------------------+\n",
      "|               0.0|\n",
      "|26.785714285714285|\n",
      "|10.989010989010989|\n",
      "|14.285714285714285|\n",
      "| 26.89075630252101|\n",
      "|20.535714285714285|\n",
      "|19.157088122605362|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|20.899470899470902|\n",
      "|22.460317460317462|\n",
      "|12.755102040816327|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|26.488095238095237|\n",
      "|               0.0|\n",
      "|27.777777777777775|\n",
      "|52.083333333333336|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "df = df.withColumn(\"tip_percentage\", col(\"tip_amount\") / (col(\"fare_amount\") + col(\"extra\") + col(\"mta_tax\")) * 100)\n",
    "tip_percentage_by_trip = df.select(\"tip_percentage\")\n",
    "tip_percentage_by_trip.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Investigate Geographical Variations in Tipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+\n",
      "|PULocationID|DOLocationID|avg_tip_percentage|\n",
      "+------------+------------+------------------+\n",
      "|         236|         238|19.420470618085226|\n",
      "|         148|         229|16.596049998818355|\n",
      "|         107|         161|18.779140825018864|\n",
      "|         229|         239|18.473992982875824|\n",
      "|         231|         140|14.708558592369055|\n",
      "|         163|         263|18.762452178520405|\n",
      "|         148|         146|12.262024871267831|\n",
      "|         163|           7|14.297723142802157|\n",
      "|         151|         116|11.741421345294407|\n",
      "|          75|          97|18.611820903910157|\n",
      "|         114|         151|16.332967217040427|\n",
      "|         231|          41|13.224851716469948|\n",
      "|         232|          45|14.435281007242583|\n",
      "|         116|         229|11.063125343574393|\n",
      "|         132|         107|17.049076096067488|\n",
      "|         264|         107|15.137765536989946|\n",
      "|         229|          36|20.521484427531213|\n",
      "|          43|           7| 17.61322964772887|\n",
      "|          49|          49| 41.91907659515524|\n",
      "|          80|         260| 10.54054054054054|\n",
      "+------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "avg_tips_by_location = df.groupBy(\"PULocationID\", \"DOLocationID\").agg(avg(\"tip_percentage\").alias(\"avg_tip_percentage\"))\n",
    "avg_tips_by_location.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Study Variations in Tipping by Time of Day, Week, and Notable Periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+------------------+\n",
      "|pickup_dayofweek|pickup_hour|avg_tip_percentage|\n",
      "+----------------+-----------+------------------+\n",
      "|               3|         22|17.262825873235595|\n",
      "|               3|         15| 17.63165910467149|\n",
      "|               7|         21|17.695372036959583|\n",
      "|               4|         10| 17.84951687890442|\n",
      "|               5|         16|16.852673672017325|\n",
      "|               6|         20|18.044354006106882|\n",
      "|               1|          0|16.113172650781422|\n",
      "|               6|          1| 35.80202971211582|\n",
      "|               3|          1| 14.51643230823709|\n",
      "|               7|          4|15.533714446235779|\n",
      "|               2|          2|16.098495399747833|\n",
      "|               6|         22|18.299501897516507|\n",
      "|               3|         13|17.518601152940352|\n",
      "|               2|         19| 17.91102047750753|\n",
      "|               7|         14|18.193513357301786|\n",
      "|               3|         18|20.090834696031795|\n",
      "|               1|          7| 15.22467917334295|\n",
      "|               2|          3|14.432236075611886|\n",
      "|               4|          7| 17.58224618306898|\n",
      "|               7|          1|17.124717031661692|\n",
      "+----------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import dayofweek, hour\n",
    "\n",
    "df = df.withColumn(\"pickup_dayofweek\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Average tip percentage by day of the week and hour\n",
    "avg_tips_by_time = df.groupBy(\"pickup_dayofweek\", \"pickup_hour\").agg(avg(\"tip_percentage\").alias(\"avg_tip_percentage\"))\n",
    "avg_tips_by_time.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Explore the Impact of Different Payment Types on Tipping Behavior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====================================>                      (5 + 3) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|payment_type|  avg_tip_percentage|\n",
      "+------------+--------------------+\n",
      "|           1|  24.987643406796913|\n",
      "|           3|0.007011956794025124|\n",
      "|           2|-0.00497977152114...|\n",
      "|           4|-0.13274535408945098|\n",
      "|           0|   7.184890628619743|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_tips_by_payment_type = df.groupBy(\"payment_type\").agg(avg(\"tip_percentage\").alias(\"avg_tip_percentage\"))\n",
    "avg_tips_by_payment_type.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# To save the results\n",
    "ANALYSED_DATA_DIR = \"../../results/analysed_data/\"\n",
    "\n",
    "avg_tips_by_location.write.format(\"parquet\").save(f\"{ANALYSED_DATA_DIR}avg_tips_by_location.parquet\")\n",
    "avg_tips_by_time.write.format(\"parquet\").save(f\"{ANALYSED_DATA_DIR}avg_tips_by_time.parquet\")\n",
    "avg_tips_by_payment_type.write.format(\"parquet\").save(f\"{ANALYSED_DATA_DIR}avg_tips_by_payment_type.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Running on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./tip_analysis.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  2.0 KiB/  2.0 KiB]                                                \n",
      "Operation completed over 1 objects/2.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Set bucket name\n",
    "bucket_name = \"spbd-nyc-taxi-bucket\"\n",
    "script_name = \"tip_analysis.py\"\n",
    "\n",
    "# Upload the Python script\n",
    "!gsutil cp ./{script_name} gs://{bucket_name}/scripts/\n",
    "\n",
    "# Upload processed data\n",
    "# !gsutil -m cp -r ../../data/processed/yellow_tripdata_2024-01.parquet gs://{bucket_name}/data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/epita-spbd-nyc-da/regions/europe-west9/operations/727c1c06-cc03-3eb5-9703-5fe614ee956d].\n",
      "Waiting for cluster creation operation...                                      \n",
      "\u001b[1;33mWARNING:\u001b[0m Consider using Auto Zone rather than selecting a zone manually. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone\n",
      "\u001b[1;33mWARNING:\u001b[0m Failed to validate permissions required for default service account: '842263258747-compute@developer.gserviceaccount.com'. Cluster creation could still be successful if required permissions have been granted to the respective service accounts as mentioned in the document https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#dataproc_service_accounts_2. This could be due to Cloud Resource Manager API hasn't been enabled in your project '842263258747' before or it is disabled. Enable it by visiting 'https://console.developers.google.com/apis/api/cloudresourcemanager.googleapis.com/overview?project=842263258747'.\n",
      "\u001b[1;33mWARNING:\u001b[0m The firewall rules for specified network or subnetwork would allow ingress traffic from 0.0.0.0/0, which could be a security risk.\n",
      "\u001b[1;33mWARNING:\u001b[0m The specified custom staging bucket 'dataproc-staging-europe-west9-842263258747-telg9nke' is not using uniform bucket level access IAM configuration. It is recommended to update bucket to enable the same. See https://cloud.google.com/storage/docs/uniform-bucket-level-access.\n",
      "Waiting for cluster creation operation...done.                                 \n",
      "Created [https://dataproc.googleapis.com/v1/projects/epita-spbd-nyc-da/regions/europe-west9/clusters/spbd-nyc-taxi-cluster] Cluster placed in zone [europe-west9-a].\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"spbd-nyc-taxi-cluster\"\n",
    "region = \"europe-west9\"\n",
    "machine_type=\"n2-standard-2\"\n",
    "\n",
    "!gcloud dataproc clusters create {cluster_name} \\\n",
    "    --region={region} \\\n",
    "    --zone={region}-a \\\n",
    "    --master-machine-type={machine_type} \\\n",
    "    --worker-machine-type={machine_type} \\\n",
    "    --num-workers=2 \\\n",
    "    --image-version=2.0-debian10 \\\n",
    "    --scopes=default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [dfeff9ec976a44f5954c582919e2b9e6] submitted.\n",
      "Waiting for job output...\n",
      "24/05/25 12:11:23 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "24/05/25 12:11:23 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "24/05/25 12:11:23 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/05/25 12:11:23 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "24/05/25 12:11:23 INFO org.sparkproject.jetty.util.log: Logging initialized @3305ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "24/05/25 12:11:23 INFO org.sparkproject.jetty.server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_412-b08\n",
      "24/05/25 12:11:23 INFO org.sparkproject.jetty.server.Server: Started @3416ms\n",
      "24/05/25 12:11:23 INFO org.sparkproject.jetty.server.AbstractConnector: Started ServerConnector@3ec3186f{HTTP/1.1, (http/1.1)}{0.0.0.0:42959}\n",
      "24/05/25 12:11:24 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at spbd-nyc-taxi-cluster-m/10.200.0.16:8032\n",
      "24/05/25 12:11:24 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at spbd-nyc-taxi-cluster-m/10.200.0.16:10200\n",
      "24/05/25 12:11:25 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found\n",
      "24/05/25 12:11:25 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "24/05/25 12:11:26 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1716638525446_0002\n",
      "24/05/25 12:11:27 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at spbd-nyc-taxi-cluster-m/10.200.0.16:8030\n",
      "24/05/25 12:11:29 INFO com.google.cloud.hadoop.fs.gcs.GhfsStorageStatistics: Detected potential high latency for operation op_get_file_status. latencyMs=234; previousMaxLatencyMs=0; operationCount=1; context=gs://dataproc-temp-europe-west9-842263258747-ucxdsplb/8428ebd7-a956-48fc-ae2d-ed3c725e3e6f/spark-job-history\n",
      "24/05/25 12:11:29 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n",
      "+------------------+\n",
      "|    tip_percentage|\n",
      "+------------------+\n",
      "|               0.0|\n",
      "|26.785714285714285|\n",
      "|10.989010989010989|\n",
      "|14.285714285714285|\n",
      "| 26.89075630252101|\n",
      "|20.535714285714285|\n",
      "|19.157088122605362|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|20.899470899470902|\n",
      "|22.460317460317462|\n",
      "|12.755102040816327|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|26.488095238095237|\n",
      "|               0.0|\n",
      "|27.777777777777775|\n",
      "|52.083333333333336|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+------------+------------------+\n",
      "|PULocationID|DOLocationID|avg_tip_percentage|\n",
      "+------------+------------+------------------+\n",
      "|         236|         238|19.420470618085268|\n",
      "|         148|         229|16.596049998818362|\n",
      "|         107|         161|18.779140825018867|\n",
      "|         229|         239|18.473992982875814|\n",
      "|         231|         140|14.708558592369059|\n",
      "|         163|         263|18.762452178520377|\n",
      "|         148|         146|12.262024871267831|\n",
      "|         163|           7|14.297723142802155|\n",
      "|         151|         116|11.741421345294404|\n",
      "|          75|          97|18.611820903910157|\n",
      "|         114|         151|16.332967217040423|\n",
      "|         231|          41|13.224851716469948|\n",
      "|         232|          45|14.435281007242585|\n",
      "|         116|         229|11.063125343574393|\n",
      "|         132|         107|17.049076096067434|\n",
      "|         264|         107|15.137765536989944|\n",
      "|         229|          36|20.521484427531213|\n",
      "|          43|           7|17.613229647728865|\n",
      "|          49|          49| 41.91907659515524|\n",
      "|          80|         260| 10.54054054054054|\n",
      "+------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+-----------+------------------+\n",
      "|pickup_dayofweek|pickup_hour|avg_tip_percentage|\n",
      "+----------------+-----------+------------------+\n",
      "|               3|         22| 17.26282587323548|\n",
      "|               3|         15|17.631659104671577|\n",
      "|               7|         21| 17.69537203695942|\n",
      "|               4|         10|17.849516878904463|\n",
      "|               5|         16| 16.85267367201719|\n",
      "|               6|         20| 18.04435400610672|\n",
      "|               1|          0|16.113172650781372|\n",
      "|               6|          1| 35.80202971211584|\n",
      "|               3|          1|14.516432308237063|\n",
      "|               7|          4|15.533714446235791|\n",
      "|               2|          2| 16.09849539974788|\n",
      "|               6|         22|18.299501897516333|\n",
      "|               3|         13|17.518601152940413|\n",
      "|               2|         19|17.911020477507456|\n",
      "|               7|         14|18.193513357301782|\n",
      "|               3|         18| 20.09083469603124|\n",
      "|               1|          7|15.224679173342961|\n",
      "|               2|          3|14.432236075611906|\n",
      "|               4|          7| 17.58224618306909|\n",
      "|               7|          1|17.124717031661618|\n",
      "+----------------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+--------------------+\n",
      "|payment_type|  avg_tip_percentage|\n",
      "+------------+--------------------+\n",
      "|           0|   7.184890628619743|\n",
      "|           1|  24.987643406787406|\n",
      "|           3|0.007011956794025127|\n",
      "|           2|-0.00497977152114...|\n",
      "|           4|-0.13274535408945107|\n",
      "+------------+--------------------+\n",
      "\n",
      "24/05/25 12:11:54 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem: Successfully repaired 'gs://spbd-nyc-taxi-bucket/results/analysed_data/avg_tips_by_location.parquet/' directory.\n",
      "24/05/25 12:11:56 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem: Successfully repaired 'gs://spbd-nyc-taxi-bucket/results/analysed_data/avg_tips_by_time.parquet/' directory.\n",
      "24/05/25 12:11:58 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem: Successfully repaired 'gs://spbd-nyc-taxi-bucket/results/analysed_data/avg_tips_by_payment_type.parquet/' directory.\n",
      "24/05/25 12:11:58 INFO org.sparkproject.jetty.server.AbstractConnector: Stopped Spark@3ec3186f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}\n",
      "Job [dfeff9ec976a44f5954c582919e2b9e6] finished successfully.\n",
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-europe-west9-842263258747-telg9nke/google-cloud-dataproc-metainfo/8428ebd7-a956-48fc-ae2d-ed3c725e3e6f/jobs/dfeff9ec976a44f5954c582919e2b9e6/\n",
      "driverOutputResourceUri: gs://dataproc-staging-europe-west9-842263258747-telg9nke/google-cloud-dataproc-metainfo/8428ebd7-a956-48fc-ae2d-ed3c725e3e6f/jobs/dfeff9ec976a44f5954c582919e2b9e6/driveroutput\n",
      "jobUuid: 49c2c27a-f482-3599-9d77-f8ea9daf7acc\n",
      "placement:\n",
      "  clusterName: spbd-nyc-taxi-cluster\n",
      "  clusterUuid: 8428ebd7-a956-48fc-ae2d-ed3c725e3e6f\n",
      "pysparkJob:\n",
      "  mainPythonFileUri: gs://spbd-nyc-taxi-bucket/scripts/tip_analysis.py\n",
      "reference:\n",
      "  jobId: dfeff9ec976a44f5954c582919e2b9e6\n",
      "  projectId: epita-spbd-nyc-da\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-05-25T12:11:59.920710Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-05-25T12:11:18.731849Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-05-25T12:11:18.770859Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-05-25T12:11:19.080980Z'\n",
      "yarnApplications:\n",
      "- name: Tip Analysis\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://spbd-nyc-taxi-cluster-m:8088/proxy/application_1716638525446_0002/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit pyspark \\\n",
    "    gs://spbd-nyc-taxi-bucket/scripts/{script_name} \\\n",
    "    --cluster={cluster_name} \\\n",
    "    --region={region}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID                            TYPE     STATUS\n",
      "dfeff9ec976a44f5954c582919e2b9e6  pyspark  DONE\n",
      "d255986775b54cf78ad6d968241cac4f  pyspark  ERROR\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs list --cluster=spbd-nyc-taxi-cluster --region=europe-west9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/epita-spbd-nyc-da/regions/europe-west9/operations/4d72374c-2092-31a6-8f8a-65a6facadd42].\n",
      "Waiting for cluster deletion operation...done.                                 \n",
      "Deleted [https://dataproc.googleapis.com/v1/projects/epita-spbd-nyc-da/regions/europe-west9/clusters/spbd-nyc-taxi-cluster].\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc clusters delete spbd-nyc-taxi-cluster --region=europe-west9 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
