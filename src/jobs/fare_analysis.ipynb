{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fare Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/25 11:58:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create or retrieve a Spark session\n",
    "spark = SparkSession.builder.appName(\"Fare Analysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Load the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROCESSED = \"../../data/processed/yellow_tripdata_2024-01.parquet\"\n",
    "\n",
    "df = spark.read.parquet(TRAIN_PROCESSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Average Fares by Pickup and Drop-off Locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+\n",
      "|PULocationID|DOLocationID|          avg_fare|\n",
      "+------------+------------+------------------+\n",
      "|         236|         238|10.041376664056385|\n",
      "|         148|         229|17.747352245862885|\n",
      "|         107|         161|13.325880842321519|\n",
      "|         229|         239| 17.84373188405798|\n",
      "|         231|         140|31.463979933110366|\n",
      "|         163|         263|14.274155279503104|\n",
      "|         148|         146|28.083333333333332|\n",
      "|         163|           7|22.235064935064933|\n",
      "|         151|         116|15.101366906474821|\n",
      "|          75|          97| 50.36666666666667|\n",
      "|         114|         151|30.727027027027034|\n",
      "|         231|          41| 39.28328358208955|\n",
      "|         232|          45|10.641904761904764|\n",
      "|         116|         229|32.286249999999995|\n",
      "|         132|         107| 68.83601078167115|\n",
      "|         264|         107|14.731111111111112|\n",
      "|         229|          36|              33.9|\n",
      "|          43|           7| 24.35576923076923|\n",
      "|          49|          49|18.763548387096776|\n",
      "|          80|         260|            16.965|\n",
      "+------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, avg\n",
    "\n",
    "avg_fares_location = df.groupBy(\"PULocationID\", \"DOLocationID\").agg(avg(\"fare_amount\").alias(\"avg_fare\"))\n",
    "avg_fares_location.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Average Fares by Passenger Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|passenger_count|          avg_fare|\n",
      "+---------------+------------------+\n",
      "|              0|17.075336405529956|\n",
      "|              7|45.411249999999995|\n",
      "|              6|17.228569319554442|\n",
      "|              5|17.511869814361592|\n",
      "|              1|17.557051804714995|\n",
      "|              3|20.041298568955217|\n",
      "|              8| 81.39098039215688|\n",
      "|              2|20.171285105269558|\n",
      "|              4|21.833799014892033|\n",
      "|              9|              11.4|\n",
      "|           NULL|20.016193904200065|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_fares_passenger = df.groupBy(\"passenger_count\").agg(avg(\"fare_amount\").alias(\"avg_fare\"))\n",
    "avg_fares_passenger.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Explore Correlations Between Fare Amounts and Trip Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         correlation|\n",
      "+--------------------+\n",
      "|0.016064980070449663|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "fare_distance_correlation = df.select(corr(\"fare_amount\", \"trip_distance\").alias(\"correlation\"))\n",
    "fare_distance_correlation.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Save and Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# To save the results\n",
    "ANALYSED_DATA_DIR = \"../../results/analysed_data/\"\n",
    "\n",
    "avg_fares_location.write.format(\"parquet\").save(f\"{ANALYSED_DATA_DIR}save_avg_fares_location.parquet\")\n",
    "avg_fares_passenger.write.format(\"parquet\").save(f\"{ANALYSED_DATA_DIR}save_avg_fares_passenger.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Running on GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./fare_analysis.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  1.5 KiB/  1.5 KiB]                                                \n",
      "Operation completed over 1 objects/1.5 KiB.                                      \n",
      "If you experience problems with multiprocessing on MacOS, they might be related to https://bugs.python.org/issue33725. You can disable multiprocessing by editing your .boto config or by adding the following flag to your command: `-o \"GSUtil:parallel_process_count=1\"`. Note that multithreading is still available even if you disable multiprocessing.\n",
      "\n",
      "Copying file://../../data/processed/yellow_tripdata_2024-01.parquet [Content-Type=application/octet-stream]...\n",
      "\\ [1/1 files][ 47.6 MiB/ 47.6 MiB] 100% Done                                    \n",
      "Operation completed over 1 objects/47.6 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Set bucket name\n",
    "bucket_name = \"spbd-nyc-taxi-bucket\"\n",
    "\n",
    "# Upload the Python script\n",
    "!gsutil cp ./fare_analysis.py gs://{bucket_name}/scripts/\n",
    "\n",
    "# Upload processed data\n",
    "!gsutil -m cp -r ../../data/processed/yellow_tripdata_2024-01.parquet gs://{bucket_name}/data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/epita-spbd-nyc-da/regions/europe-west9/operations/79225936-e5f7-3e92-98cd-6b458a09d76c].\n",
      "Waiting for cluster creation operation...                                      \n",
      "\u001b[1;33mWARNING:\u001b[0m Consider using Auto Zone rather than selecting a zone manually. See https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/auto-zone\n",
      "\u001b[1;33mWARNING:\u001b[0m Failed to validate permissions required for default service account: '842263258747-compute@developer.gserviceaccount.com'. Cluster creation could still be successful if required permissions have been granted to the respective service accounts as mentioned in the document https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/service-accounts#dataproc_service_accounts_2. This could be due to Cloud Resource Manager API hasn't been enabled in your project '842263258747' before or it is disabled. Enable it by visiting 'https://console.developers.google.com/apis/api/cloudresourcemanager.googleapis.com/overview?project=842263258747'.\n",
      "\u001b[1;33mWARNING:\u001b[0m The firewall rules for specified network or subnetwork would allow ingress traffic from 0.0.0.0/0, which could be a security risk.\n",
      "\u001b[1;33mWARNING:\u001b[0m The specified custom staging bucket 'dataproc-staging-europe-west9-842263258747-telg9nke' is not using uniform bucket level access IAM configuration. It is recommended to update bucket to enable the same. See https://cloud.google.com/storage/docs/uniform-bucket-level-access.\n",
      "Waiting for cluster creation operation...done.                                 \n",
      "Created [https://dataproc.googleapis.com/v1/projects/epita-spbd-nyc-da/regions/europe-west9/clusters/spbd-nyc-taxi-cluster] Cluster placed in zone [europe-west9-a].\n"
     ]
    }
   ],
   "source": [
    "cluster_name = \"spbd-nyc-taxi-cluster\"\n",
    "region = \"europe-west9\"\n",
    "machine_type=\"n2-standard-2\"\n",
    "\n",
    "!gcloud dataproc clusters create {cluster_name} \\\n",
    "    --region={region} \\\n",
    "    --zone={region}-a \\\n",
    "    --master-machine-type={machine_type} \\\n",
    "    --worker-machine-type={machine_type} \\\n",
    "    --num-workers=2 \\\n",
    "    --image-version=2.0-debian10 \\\n",
    "    --scopes=default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [d15df5b9e4684d76afc7b7ec6b5534ea] submitted.\n",
      "Waiting for job output...\n",
      "24/05/25 11:38:53 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "24/05/25 11:38:53 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "24/05/25 11:38:53 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/05/25 11:38:54 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n",
      "24/05/25 11:38:54 INFO org.sparkproject.jetty.util.log: Logging initialized @4352ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
      "24/05/25 11:38:54 INFO org.sparkproject.jetty.server.Server: jetty-9.4.40.v20210413; built: 2021-04-13T20:42:42.668Z; git: b881a572662e1943a14ae12e7e1207989f218b74; jvm 1.8.0_412-b08\n",
      "24/05/25 11:38:54 INFO org.sparkproject.jetty.server.Server: Started @4479ms\n",
      "24/05/25 11:38:54 INFO org.sparkproject.jetty.server.AbstractConnector: Started ServerConnector@a1a67f3{HTTP/1.1, (http/1.1)}{0.0.0.0:37269}\n",
      "24/05/25 11:38:55 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at spbd-nyc-taxi-cluster-m/10.200.0.13:8032\n",
      "24/05/25 11:38:55 INFO org.apache.hadoop.yarn.client.AHSProxy: Connecting to Application History server at spbd-nyc-taxi-cluster-m/10.200.0.13:10200\n",
      "24/05/25 11:38:57 INFO org.apache.hadoop.conf.Configuration: resource-types.xml not found\n",
      "24/05/25 11:38:57 INFO org.apache.hadoop.yarn.util.resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "24/05/25 11:38:58 INFO org.apache.hadoop.yarn.client.api.impl.YarnClientImpl: Submitted application application_1716637066579_0001\n",
      "24/05/25 11:38:59 INFO org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at spbd-nyc-taxi-cluster-m/10.200.0.13:8030\n",
      "24/05/25 11:39:01 INFO com.google.cloud.hadoop.fs.gcs.GhfsStorageStatistics: Detected potential high latency for operation op_get_file_status. latencyMs=228; previousMaxLatencyMs=0; operationCount=1; context=gs://dataproc-temp-europe-west9-842263258747-ucxdsplb/1410b153-1ad7-4ec2-8c79-1a1ddbff9a5a/spark-job-history\n",
      "24/05/25 11:39:01 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n",
      "+------------+------------+------------------+\n",
      "|PULocationID|DOLocationID|          avg_fare|\n",
      "+------------+------------+------------------+\n",
      "|         236|         238| 10.04137666405639|\n",
      "|         132|         107| 68.83601078167115|\n",
      "|          43|         100|16.083343750000008|\n",
      "|         134|          95|             13.02|\n",
      "|         163|         263|14.274155279503109|\n",
      "|         100|         140| 19.04947626841244|\n",
      "|         107|         161|13.325880842321506|\n",
      "|         231|         140| 31.46397993311036|\n",
      "|         229|         239|17.843731884057974|\n",
      "|         231|          41| 39.28328358208956|\n",
      "|          75|         200|42.916666666666664|\n",
      "|         151|         116|15.101366906474821|\n",
      "|         148|         229|17.747352245862892|\n",
      "|         264|         107|14.731111111111112|\n",
      "|         114|         151| 30.72702702702703|\n",
      "|         141|         173|30.435999999999993|\n",
      "|         259|         259| 31.05666666666666|\n",
      "|         244|          50|27.805333333333337|\n",
      "|         236|          45| 33.89666666666667|\n",
      "|         247|         163|              33.5|\n",
      "+------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+------------------+\n",
      "|passenger_count|          avg_fare|\n",
      "+---------------+------------------+\n",
      "|              0|17.075336405529896|\n",
      "|              7|45.411249999999995|\n",
      "|              6|  17.2285693195544|\n",
      "|              9|              11.4|\n",
      "|              5|17.511869814361543|\n",
      "|           null|20.016193904200065|\n",
      "|              1|17.557051804717617|\n",
      "|              3|20.041298568955362|\n",
      "|              8| 81.39098039215685|\n",
      "|              2|20.171285105269323|\n",
      "|              4| 21.83379901489209|\n",
      "+---------------+------------------+\n",
      "\n",
      "+--------------------+\n",
      "|         correlation|\n",
      "+--------------------+\n",
      "|0.016064980070449545|\n",
      "+--------------------+\n",
      "\n",
      "24/05/25 11:39:29 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem: Successfully repaired 'gs://spbd-nyc-taxi-bucket/results/analysed_data/avg_fares_location.parquet/' directory.\n",
      "24/05/25 11:39:29 INFO com.google.cloud.hadoop.fs.gcs.GhfsStorageStatistics: Detected potential high latency for operation op_delete. latencyMs=403; previousMaxLatencyMs=0; operationCount=1; context=gs://spbd-nyc-taxi-bucket/results/analysed_data/avg_fares_location.parquet/_temporary\n",
      "24/05/25 11:39:31 INFO com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystem: Successfully repaired 'gs://spbd-nyc-taxi-bucket/results/analysed_data/avg_fares_passenger.parquet/' directory.\n",
      "24/05/25 11:39:31 INFO org.sparkproject.jetty.server.AbstractConnector: Stopped Spark@a1a67f3{HTTP/1.1, (http/1.1)}{0.0.0.0:0}\n",
      "24/05/25 11:39:32 INFO com.google.cloud.hadoop.fs.gcs.GhfsStorageStatistics: Detected potential high latency for operation op_rename. latencyMs=158; previousMaxLatencyMs=0; operationCount=1; context=rename(gs://dataproc-temp-europe-west9-842263258747-ucxdsplb/1410b153-1ad7-4ec2-8c79-1a1ddbff9a5a/spark-job-history/application_1716637066579_0001.inprogress -> gs://dataproc-temp-europe-west9-842263258747-ucxdsplb/1410b153-1ad7-4ec2-8c79-1a1ddbff9a5a/spark-job-history/application_1716637066579_0001)\n",
      "Job [d15df5b9e4684d76afc7b7ec6b5534ea] finished successfully.\n",
      "done: true\n",
      "driverControlFilesUri: gs://dataproc-staging-europe-west9-842263258747-telg9nke/google-cloud-dataproc-metainfo/1410b153-1ad7-4ec2-8c79-1a1ddbff9a5a/jobs/d15df5b9e4684d76afc7b7ec6b5534ea/\n",
      "driverOutputResourceUri: gs://dataproc-staging-europe-west9-842263258747-telg9nke/google-cloud-dataproc-metainfo/1410b153-1ad7-4ec2-8c79-1a1ddbff9a5a/jobs/d15df5b9e4684d76afc7b7ec6b5534ea/driveroutput\n",
      "jobUuid: 9f9fe6d4-6069-3c3e-98b6-015e52bc4ad8\n",
      "placement:\n",
      "  clusterName: spbd-nyc-taxi-cluster\n",
      "  clusterUuid: 1410b153-1ad7-4ec2-8c79-1a1ddbff9a5a\n",
      "pysparkJob:\n",
      "  mainPythonFileUri: gs://spbd-nyc-taxi-bucket/scripts/fare_analysis.py\n",
      "reference:\n",
      "  jobId: d15df5b9e4684d76afc7b7ec6b5534ea\n",
      "  projectId: epita-spbd-nyc-da\n",
      "status:\n",
      "  state: DONE\n",
      "  stateStartTime: '2024-05-25T11:39:35.448755Z'\n",
      "statusHistory:\n",
      "- state: PENDING\n",
      "  stateStartTime: '2024-05-25T11:38:47.846906Z'\n",
      "- state: SETUP_DONE\n",
      "  stateStartTime: '2024-05-25T11:38:47.884460Z'\n",
      "- details: Agent reported job success\n",
      "  state: RUNNING\n",
      "  stateStartTime: '2024-05-25T11:38:48.463238Z'\n",
      "yarnApplications:\n",
      "- name: Fare Analysis\n",
      "  progress: 1.0\n",
      "  state: FINISHED\n",
      "  trackingUrl: http://spbd-nyc-taxi-cluster-m:8088/proxy/application_1716637066579_0001/\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs submit pyspark \\\n",
    "    gs://spbd-nyc-taxi-bucket/scripts/fare_analysis.py \\\n",
    "    --cluster={cluster_name} \\\n",
    "    --region={region}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_ID                            TYPE     STATUS\n",
      "d15df5b9e4684d76afc7b7ec6b5534ea  pyspark  DONE\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc jobs list --cluster=spbd-nyc-taxi-cluster --region=europe-west9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on operation [projects/epita-spbd-nyc-da/regions/europe-west9/operations/39f55afd-d2ae-306a-8858-61393d54b6c8].\n",
      "Waiting for cluster deletion operation...done.                                 \n",
      "Deleted [https://dataproc.googleapis.com/v1/projects/epita-spbd-nyc-da/regions/europe-west9/clusters/spbd-nyc-taxi-cluster].\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc clusters delete spbd-nyc-taxi-cluster --region=europe-west9 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis_spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
